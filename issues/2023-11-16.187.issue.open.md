# [\#187 Issue](https://github.com/OWASP/www-project-machine-learning-security-top-10/issues/187) `open`: [FEEDBACK]: Sync attack names between LLMT10 and MLT10 where appropriate
**Labels**: `issues/general`, `issues/triage`


#### <img src="https://avatars.githubusercontent.com/u/795878?u=d704fd433504e531d707c517cdb6ff75bdf20372&v=4" width="50">[kapsolas](https://github.com/kapsolas) opened issue at [2023-11-16 22:16](https://github.com/OWASP/www-project-machine-learning-security-top-10/issues/187):

### Type

Suggestions for Improvement

### What would you like to report?

I would like to make the suggestion that we consolidate the terms used in the LLM and ML top 10 documents.

Many of the top 10 items in each are closely related or even the same.
Where possible, the same term should be used (i.e. Model Theft vs Model Stealing, Data Poisoning Attack vs Training data Poisoning).

Thanks!

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct

#### <img src="https://avatars.githubusercontent.com/u/412800?v=4" width="50">[shsingh](https://github.com/shsingh) commented at [2023-12-18 04:03](https://github.com/OWASP/www-project-machine-learning-security-top-10/issues/187#issuecomment-1859515638):

Hi @kapsolas apologies for the delay in responsing.

Will definitely look to changing "Model Stealing" to "Model Theft". 

In terms of "Data Poisoning v Training data poisoning" I would like to defer to @yodap-dg 

Typically in research papers it is referred to as "Data Poisoning" and I agree that the use case is largely around the training data itself.

What are your thoughts @yodap-dg?


-------------------------------------------------------------------------------



[Export of Github issue for [OWASP/www-project-machine-learning-security-top-10](https://github.com/OWASP/www-project-machine-learning-security-top-10).]
